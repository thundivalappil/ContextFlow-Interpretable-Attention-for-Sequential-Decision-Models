# Social / Publishing Pack (Copy–Paste)

## 1) GitHub Repo Title (high-click)
**ContextFlow — Interpretable Attention for Time-Series & Event Sequences (PyTorch)**

## 2) One-line tagline
*Predict + explain: learn which time steps mattered most.*

## 3) 350-character GitHub summary (tight + view-optimized)
ContextFlow is a compact PyTorch project that learns attention-style influence weights over sequences, returning both predictions and an interpretable time-step importance map. Built with clean training/inference scripts + synthetic data—easy to swap in real finance/log/event streams.

## 4) LinkedIn post (short + strong)
I just published **ContextFlow** — a lightweight PyTorch project that doesn’t just predict from sequences, it **explains which time steps drove the decision** (attention-style influence map).

Why it matters:
• Time-series signal detection (finance/ops)  
• Event-sequence risk scoring (fraud/logs)  
• Interpretable anomaly discovery  

Try it:
`python run.py train`  
`python run.py infer --topk 5`

If you want a “full Transformer mini-version”, next upgrades: positional encoding + multi-head + Add&Norm + FFN.

## 5) Hashtags
#PyTorch #Attention #ExplainableAI #TimeSeries #MachineLearning #DataScience #AI #AnomalyDetection #FraudDetection #FinTech #MLOps #OpenSource
